{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18556093-ab77-49bd-b354-cd855c7978fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd4c707-cb20-4c24-8819-529776297421",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r\"C:\\Users\\hsynt\\Downloads\\Selcuk Abi\\Selcuk Abi\\VeriSeti2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7038c6ed-10ff-4944-bc25-8c577ec63cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8218 - loss: 0.4141\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8686 - loss: 0.3154\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8724 - loss: 0.3065\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.2912\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8760 - loss: 0.2911\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8755 - loss: 0.2893\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.2872\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.2797\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8784 - loss: 0.2820\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.2724\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8172 - loss: 0.4195\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8698 - loss: 0.3169\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8713 - loss: 0.3033\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8743 - loss: 0.2982\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8755 - loss: 0.2964\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8747 - loss: 0.2919\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8785 - loss: 0.2862\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8740 - loss: 0.2882\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8772 - loss: 0.2837\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.2748\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8206 - loss: 0.4242\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8690 - loss: 0.3150\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8718 - loss: 0.3034\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8726 - loss: 0.3002\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8768 - loss: 0.2927\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.2861\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.2862\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8750 - loss: 0.2869\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.2862\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.2840\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7616 - loss: 0.5334\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7908 - loss: 0.4813\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7895 - loss: 0.4763\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7977 - loss: 0.4702\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7966 - loss: 0.4667\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 0.4615\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4656\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7966 - loss: 0.4688\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7992 - loss: 0.4649\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7989 - loss: 0.4650\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.5367\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7980 - loss: 0.4791\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.4644\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7988 - loss: 0.4684\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8012 - loss: 0.4629\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.4676\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8007 - loss: 0.4633\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 0.4637\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.4669\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.4660\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7566 - loss: 0.5260\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7973 - loss: 0.4719\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8000 - loss: 0.4673\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.4719\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7972 - loss: 0.4686\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7963 - loss: 0.4704\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7986 - loss: 0.4669\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7968 - loss: 0.4655\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7990 - loss: 0.4600\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7955 - loss: 0.4679\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3508\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.3125\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.3154\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8679 - loss: 0.3092\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8673 - loss: 0.3107\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8661 - loss: 0.3154\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8645 - loss: 0.3136\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3083\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8685 - loss: 0.3092\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8644 - loss: 0.3115\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8570 - loss: 0.3441\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.3195\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.3155\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8679 - loss: 0.3113\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 0.3097\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8652 - loss: 0.3167\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8695 - loss: 0.3092\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8645 - loss: 0.3125\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8645 - loss: 0.3161\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3151\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8521 - loss: 0.3545\n",
      "Epoch 2/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3124\n",
      "Epoch 3/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.3153\n",
      "Epoch 4/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3162\n",
      "Epoch 5/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3180\n",
      "Epoch 6/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8648 - loss: 0.3128\n",
      "Epoch 7/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.3103\n",
      "Epoch 8/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8690 - loss: 0.3117\n",
      "Epoch 9/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8657 - loss: 0.3134\n",
      "Epoch 10/10\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 0.3136\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step\n",
      "Eğitim ve Test Süreleri Tablosu:\n",
      "             Reduction Model  Train Time (s)  Test Time (s)\n",
      "0  No PCA/LDA (Fold 1)   MLP       13.408718       0.665182\n",
      "1  No PCA/LDA (Fold 2)   MLP       13.930806       0.626168\n",
      "2  No PCA/LDA (Fold 3)   MLP       13.529936       0.524207\n",
      "3         PCA (Fold 1)   MLP       12.886685       0.508695\n",
      "4         PCA (Fold 2)   MLP       12.830356       0.504787\n",
      "5         PCA (Fold 3)   MLP       12.971883       0.542551\n",
      "6         LDA (Fold 1)   MLP       13.269392       0.655425\n",
      "7         LDA (Fold 2)   MLP       13.613743       0.495856\n",
      "8         LDA (Fold 3)   MLP       12.944850       0.538472\n",
      "\n",
      "Sonuçlar 'mlp_kfold_train_test_times.csv' dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Özellik ve Hedef Ayrımı\n",
    "X = data.drop(columns=['Target_10', 'adjclose'])\n",
    "y = data['Target_10']\n",
    "\n",
    "# Zaman Serisi Formatına Getirme\n",
    "def create_sequences(data, target, seq_length):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length].flatten())  # MLP için düzleştirilmiş giriş\n",
    "        targets.append(target[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "SEQ_LENGTH = 10\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, SEQ_LENGTH)\n",
    "\n",
    "# PCA ve LDA Veri Hazırlığı\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_seq)\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_lda = lda.fit_transform(X_seq, y_seq)\n",
    "\n",
    "# MLP Modeli Tanımlama\n",
    "def build_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_shape,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Eğitim ve Test Sürelerini Hesaplama\n",
    "results = []\n",
    "\n",
    "for reduction, X_data in zip(\n",
    "    ['No PCA/LDA', 'PCA', 'LDA'],\n",
    "    [X_seq, X_pca, X_lda]\n",
    "):\n",
    "    fold_num = 1\n",
    "    for train_idx, test_idx in kfold.split(X_data, y_seq):\n",
    "        # Eğitim ve Test Bölünmesi\n",
    "        X_train, X_test = X_data[train_idx], X_data[test_idx]\n",
    "        y_train, y_test = y_seq[train_idx], y_seq[test_idx]\n",
    "\n",
    "        # Modeli Oluştur ve Eğit\n",
    "        mlp_model = build_mlp_model(X_train.shape[1])\n",
    "\n",
    "        # Eğitim Süresi Ölçümü\n",
    "        start_time = time.time()\n",
    "        mlp_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # Test Süresi Ölçümü\n",
    "        start_time = time.time()\n",
    "        mlp_model.predict(X_test)\n",
    "        test_time = time.time() - start_time\n",
    "\n",
    "        results.append({\n",
    "            'Reduction': f\"{reduction} (Fold {fold_num})\",\n",
    "            'Model': 'MLP',\n",
    "            'Train Time (s)': train_time,\n",
    "            'Test Time (s)': test_time\n",
    "        })\n",
    "\n",
    "        fold_num += 1\n",
    "\n",
    "# Performans Sonuçlarını Görselleştirme\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Eğitim ve Test Süreleri Tablosu\n",
    "print(\"Eğitim ve Test Süreleri Tablosu:\")\n",
    "print(results_df)\n",
    "\n",
    "# Sonuçları Kaydetme\n",
    "results_df.to_csv(\"mlp_kfold_train_test_times.csv\", index=False)\n",
    "print(\"\\nSonuçlar 'mlp_kfold_train_test_times.csv' dosyasına kaydedildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
