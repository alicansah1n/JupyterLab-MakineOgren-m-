{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d557dd9-0240-4619-8497-4bf610c830a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81bec29-bddd-4764-9a83-82dd0562c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r\"C:\\Users\\hsynt\\Downloads\\Selcuk Abi\\Selcuk Abi\\VeriSeti2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96484ec5-86c8-443b-a2b0-98e375b17aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8248 - loss: 0.4158\n",
      "Epoch 2/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8697 - loss: 0.3157\n",
      "Epoch 3/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8737 - loss: 0.3045\n",
      "Epoch 4/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8769 - loss: 0.2950\n",
      "Epoch 5/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.2911\n",
      "Epoch 6/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8805 - loss: 0.2848\n",
      "Epoch 7/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.2870\n",
      "Epoch 8/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.2811\n",
      "Epoch 9/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8781 - loss: 0.2847\n",
      "Epoch 10/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8835 - loss: 0.2741\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.5218\n",
      "Epoch 2/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.4774\n",
      "Epoch 3/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7978 - loss: 0.4731\n",
      "Epoch 4/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.4695\n",
      "Epoch 5/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.4684\n",
      "Epoch 6/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.4635\n",
      "Epoch 7/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.4662\n",
      "Epoch 8/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.4655\n",
      "Epoch 9/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7991 - loss: 0.4681\n",
      "Epoch 10/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4644\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8673 - loss: 0.3386\n",
      "Epoch 2/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8652 - loss: 0.3185\n",
      "Epoch 3/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3090\n",
      "Epoch 4/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3108\n",
      "Epoch 5/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.3084\n",
      "Epoch 6/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8661 - loss: 0.3126\n",
      "Epoch 7/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8669 - loss: 0.3137\n",
      "Epoch 8/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3123\n",
      "Epoch 9/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8685 - loss: 0.3113\n",
      "Epoch 10/10\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8661 - loss: 0.3120\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step\n",
      "\u001b[1m1249/1249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step\n",
      "Eğitim Kümesi Performans Sonuçları:\n",
      "                  Accuracy  Precision     Recall   F1-Score        AUC\n",
      "Reduction Model                                                       \n",
      "None      MLP    88.647851  89.006634  91.235042  90.107063  95.699119\n",
      "PCA       MLP    80.158134  82.157060  83.013203  82.582912  86.262381\n",
      "LDA       MLP    86.776260  87.700860  89.168543  88.428612  93.977393\n",
      "\n",
      "Test Kümesi Performans Sonuçları:\n",
      "                  Accuracy  Precision     Recall   F1-Score        AUC\n",
      "Reduction Model                                                       \n",
      "None      MLP    87.610088  87.657474  90.939597  89.268377  94.681010\n",
      "PCA       MLP    79.233387  81.002593  82.762275  81.872980  85.541175\n",
      "LDA       MLP    86.329063  87.278723  88.820205  88.042717  93.510654\n",
      "\n",
      "Sonuçlar 'mlp_pca_lda_train_performance.csv' ve 'mlp_pca_lda_test_performance.csv' dosyalarına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Özellik ve Hedef Ayrımı\n",
    "X = data.drop(columns=['Target_10', 'adjclose'])\n",
    "y = data['Target_10']\n",
    "\n",
    "# Zaman Serisi Formatına Getirme\n",
    "def create_sequences(data, target, seq_length):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length].flatten())  # Flatten sequences for MLP\n",
    "        targets.append(target[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "SEQ_LENGTH = 10\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, SEQ_LENGTH)\n",
    "\n",
    "# Eğitim ve test kümelerinin oluşturulması\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq)\n",
    "\n",
    "# PCA ve LDA Veri Hazırlığı\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "# Performans Metriklerini Hesaplama\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred) * 100,\n",
    "        \"Precision\": precision_score(y_true, y_pred) * 100,\n",
    "        \"Recall\": recall_score(y_true, y_pred) * 100,\n",
    "        \"F1-Score\": f1_score(y_true, y_pred) * 100,\n",
    "        \"AUC\": roc_auc_score(y_true, y_pred_proba) * 100\n",
    "    }\n",
    "\n",
    "# MLP Modeli Tanımlama\n",
    "def build_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_shape,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Performansları Değerlendirme\n",
    "results_train = []\n",
    "results_test = []\n",
    "\n",
    "for reduction, X_tr, X_te, y_tr, y_te in zip(\n",
    "    ['None', 'PCA', 'LDA'],\n",
    "    [X_train, X_train_pca, X_train_lda],\n",
    "    [X_test, X_test_pca, X_test_lda],\n",
    "    [y_train, y_train, y_train],  # Aynı y_train değerlerini kullanıyoruz\n",
    "    [y_test, y_test, y_test]      # Aynı y_test değerlerini kullanıyoruz\n",
    "):\n",
    "    mlp_model = build_mlp_model(X_tr.shape[1])\n",
    "    mlp_model.fit(X_tr, y_tr, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Eğitim Performansı\n",
    "    y_train_pred = (mlp_model.predict(X_tr) > 0.5).astype(\"int32\").flatten()\n",
    "    y_train_proba = mlp_model.predict(X_tr).flatten()\n",
    "    train_metrics = calculate_metrics(y_tr, y_train_pred, y_train_proba)\n",
    "    train_metrics['Reduction'] = reduction\n",
    "    train_metrics['Model'] = 'MLP'\n",
    "    results_train.append(train_metrics)\n",
    "\n",
    "    # Test Performansı\n",
    "    y_test_pred = (mlp_model.predict(X_te) > 0.5).astype(\"int32\").flatten()\n",
    "    y_test_proba = mlp_model.predict(X_te).flatten()\n",
    "    test_metrics = calculate_metrics(y_te, y_test_pred, y_test_proba)\n",
    "    test_metrics['Reduction'] = reduction\n",
    "    test_metrics['Model'] = 'MLP'\n",
    "    results_test.append(test_metrics)\n",
    "\n",
    "# Eğitim ve Test Sonuçlarını Görselleştirme\n",
    "train_df = pd.DataFrame(results_train).set_index([\"Reduction\", \"Model\"])\n",
    "test_df = pd.DataFrame(results_test).set_index([\"Reduction\", \"Model\"])\n",
    "\n",
    "# Eğitim Sonuçları Tablosu\n",
    "print(\"Eğitim Kümesi Performans Sonuçları:\")\n",
    "print(train_df)\n",
    "\n",
    "# Test Sonuçları Tablosu\n",
    "print(\"\\nTest Kümesi Performans Sonuçları:\")\n",
    "print(test_df)\n",
    "\n",
    "# Sonuçları Kaydetme\n",
    "train_df.to_csv(\"mlp_pca_lda_train_performance.csv\")\n",
    "test_df.to_csv(\"mlp_pca_lda_test_performance.csv\")\n",
    "print(\"\\nSonuçlar 'mlp_pca_lda_train_performance.csv' ve 'mlp_pca_lda_test_performance.csv' dosyalarına kaydedildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
